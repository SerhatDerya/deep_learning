{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251e5d56-e86c-464a-a36e-efae87185ff8",
   "metadata": {},
   "source": [
    "## Optimize tensorflow pipeline performance with prefetch and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b6be07-b8c5-40ad-9255-661c54c4f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc6313c-6e3d-4054-ad47-9fff39225bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b7286-5345-4490-bb9c-11f9537958d2",
   "metadata": {},
   "source": [
    "# Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebd3a14-e81e-448b-ab80-5c1038a34deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDataset(tf.data.Dataset):\n",
    "    def read_file_in_batches(num_samples):\n",
    "        # Opening the file\n",
    "        time.sleep(0.03)\n",
    "\n",
    "        for sample_idx in range(num_samples):\n",
    "            # Reading data (line, record) from the file\n",
    "            time.sleep(0.015)\n",
    "\n",
    "            yield (sample_idx,)\n",
    "\n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls.read_file_in_batches,\n",
    "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
    "            args=(num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c7e7b9-f1e8-4423-baf5-9d1bfedf307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534bc7af-26b9-462d-8058-60d5c35f8799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:54:17.296359: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-17 16:54:17.296693: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-02-17 16:54:17.335442: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 ms ± 6.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbc67a6-60f8-4c2b-8f89-dd9e9eb479cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 ms ± 8.91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset().prefetch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6bad67-6435-4e5d-a578-8b3b6938a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 ms ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8dcf5-0b8b-4a62-87ec-17b00c83fd91",
   "metadata": {},
   "source": [
    "# Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c14391-d079-49c1-bd39-b72cb6924a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:55:46.008798: W tensorflow/core/kernels/data/cache_dataset_ops.cc:296] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "dataset = dataset.map(lambda x: x**2)\n",
    "dataset = dataset.cache(\"mycache.txt\")\n",
    "# The first time reading through the data will generate the data using\n",
    "# `range` and `map`.\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "920a768f-c297-45a3-849e-13bd5f6ff107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsequent iterations read from the cache.\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592e928e-564a-49f8-ab70-0b6a6e6d8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    # Do some hard pre-processing\n",
    "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6097d085-3f7f-480c-8664-dce3512dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "benchmark(FileDataset().map(mapped_function), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440e10b2-df3d-4a6a-8b0a-f8a01f5df584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "benchmark(FileDataset().map(mapped_function).cache(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c074e58-9b7c-48a8-b797-6e615d8c4b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
